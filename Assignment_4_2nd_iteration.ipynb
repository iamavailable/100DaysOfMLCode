{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_4_2st_iteration.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourangshupal/100DaysOfMLCode/blob/master/Assignment_4_2nd_iteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkv5tgdvgCNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMVnzCNOB83g",
        "colab_type": "text"
      },
      "source": [
        "# Building the second model architecture for MNIST dataset\n",
        "\n",
        "## Objective\n",
        "\n",
        "1. **Less than 15000 parameters**\n",
        "2. **Validation accuracy to be acheived 99.40**\n",
        "\n",
        "\n",
        "### Building our second model which will be an advancement over the simple vanilla network which we built in our previous code file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPvJaScdf7fv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7422476-d064-42d8-d5cf-75f4521c209a"
      },
      "source": [
        "# https://keras.io/\n",
        "#We are first installing the keras package via pip install and importing the keras package\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW_dCluugDs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing the numpy package with the alias np\n",
        "import numpy as np\n",
        "\n",
        "# importing sequential model from keras.models\n",
        "from keras.models import Sequential\n",
        "# importing different layers and activations from keras.layers\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "# importing np_utils from keras.utils\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# importing the mnist dataset from keras.datasets \n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4PQmX4ogGIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1475ac84-b118-4884-e073-e0a49df92c3d"
      },
      "source": [
        "# we are downloading the MNIST dataset and splitting the data for training and testing\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G0zM4plgXpb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "d30f03bf-eeeb-457b-99f1-0ceab95a0a8a"
      },
      "source": [
        "\n",
        "# printing out the shape of x_train\n",
        "print (X_train.shape)\n",
        "\n",
        "# importing pyplot with alias plt from matplotlib package\n",
        "from matplotlib import pyplot as plt\n",
        "# %matplotlib inline is a magic function to show us the plots in a notebook\n",
        "%matplotlib inline\n",
        "# plotting the first image or the image at index zero in the training dataset\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6edf913668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNZcuD82gYxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping our training and testing datatset using numpy's reshape function which we will feed to the model\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdDYmShDggAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Doing type conversion or changing the datatype to float32 for the data\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "#Doing standardization or normalization here dividind each pixel by 255 in the train and test data\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKUbCIt9gjdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bd01d64-0fce-48cb-9a59-11eff18dfbd6"
      },
      "source": [
        "#Checking first 10 image labels\n",
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8sWlOzdgmOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "# simply we can say we are doing sort of onehot encoding\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIPZ9W50grFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "cf9e4865-5028-42c9-8286-6ce6a38312ec"
      },
      "source": [
        "# having a look in the first 10 datapoints after onehot encoding\n",
        "Y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_62eCaCgtPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing warnings to filter out warnings which are sometimes annoying.\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEdQYf3MgyxV",
        "colab_type": "text"
      },
      "source": [
        "## Model Architecture 2\n",
        "\n",
        "Here we will be doing some improvements over the simple vanilla network\n",
        "\n",
        "### Improvements which will be done in the previous network are\n",
        "1. Addition of **1x1 convolution**\n",
        "2. Addition of **BatchNormalization after each convolution layer**\n",
        "\n",
        "\n",
        "Hope to see some improvements in our results. Our last result or the validation accuracy was 99.15. We are hoping to get result above 99.15.\n",
        "\n",
        "Let's see how this architecture performs.\n",
        "\n",
        "\n",
        "*Maximum 3 can be done. We are doing only 2 improvements so rule is not broken.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zViGADNcg1Ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing Activation, BatchNormalization and MaxPooling2D from keras.layers for performing maxpooling and batchnormalizing operations and adding non linearity via activation functions\n",
        "from keras.layers import Activation,BatchNormalization\n",
        "# building our sequential model using the Sequential class and creating the model object\n",
        "model = Sequential()\n",
        "# Performing 3x3 2dconvolution with 10 kernels followed by BatchNormalization layer\n",
        "model.add(Convolution2D(10,3,3, activation=\"relu\", input_shape=(28,28,1)))#channel dimensions = 26x26x10    and Receptive field = 3x3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Performing 3x3 2dconvolution with 20 kernels followed by BatchNormalization layer\n",
        "model.add(Convolution2D(20,3,3, activation=\"relu\"))                       #channel dimensions = 26x26x10    and Receptive field = 5x5\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Performing 3x3 2dconvolution with 10 kernels followed by BatchNormalization layer\n",
        "model.add(Convolution2D(10,3,3, activation=\"relu\"))                       #channel dimensions = 26x26x10    and Receptive field = 7x7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))                                  #channel dimensions = 26x26x10    and Receptive field = 14x14\n",
        "# Performing 1x1 2dconvolution with 10 kernels followed by BatchNormalization layer\n",
        "model.add(Convolution2D(10, 1, 1, activation='relu'))                     #channel dimensions = 26x26x10    and Receptive field = 14x14\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Performing 3x3 2dconvolution with 16 kernels followed by BatchNormalization layer\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))                     #channel dimensions = 26x26x10    and Receptive field = 16x16\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Performing 3x3 2dconvolution with 16 kernels followed by BatchNormalization layer\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))                     #channel dimensions = 26x26x10    and Receptive field = 18x18\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Performing 3x3 2dconvolution with 16 kernels followed by BatchNormalization layer\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))                     #channel dimensions = 26x26x10    and Receptive field = 20x20\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Performing 3x3 2dconvolution with 16 kernels followed by BatchNormalization layer\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))                     #channel dimensions = 26x26x10    and Receptive field = 22x22\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Performing 3x3 2dconvolution with 10 kernels\n",
        "model.add(Convolution2D(10, 3, 3))                                        #channel dimensions = 26x26x10    and Receptive field = 24x24\n",
        "\n",
        "\n",
        "# Here we are Flateening our dat i.e making it one dimensional which we will feed to the network.\n",
        "model.add(Flatten())\n",
        "#Using softmax activation function at the last layer which is used for multi class classification\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpap54OZhQd7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "ea61bc82-7702-4668-db15-41460e8f94ad"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 24, 24, 20)        1820      \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 22, 22, 10)        1810      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 11, 11, 10)        110       \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 5, 5, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 3, 3, 16)          2320      \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 1, 1, 10)          1450      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,706\n",
            "Trainable params: 13,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDlrcOh7EwMW",
        "colab_type": "text"
      },
      "source": [
        "### Total number of parameters are 13706 which is below 15000 so we are good to move to train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFtxI_aghRxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We are importing the Adam Optimizer\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhAWkKA3hvrZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "0e712558-7826-4648-8d4d-e8e4c8b78380"
      },
      "source": [
        "model.fit(X_train, Y_train, batch_size=32, nb_epoch=20, verbose=1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 23s 388us/step - loss: 0.2066 - acc: 0.9372\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 23s 377us/step - loss: 0.0636 - acc: 0.9805\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 21s 355us/step - loss: 0.0484 - acc: 0.9849\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 21s 358us/step - loss: 0.0400 - acc: 0.9880\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 22s 359us/step - loss: 0.0355 - acc: 0.9888\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 22s 373us/step - loss: 0.0314 - acc: 0.9902\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 21s 352us/step - loss: 0.0278 - acc: 0.9914\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 21s 350us/step - loss: 0.0257 - acc: 0.9918\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 22s 368us/step - loss: 0.0226 - acc: 0.9931\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 21s 356us/step - loss: 0.0212 - acc: 0.9931\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 21s 351us/step - loss: 0.0186 - acc: 0.9940\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 23s 378us/step - loss: 0.0182 - acc: 0.9940\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 22s 374us/step - loss: 0.0168 - acc: 0.9945\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 21s 351us/step - loss: 0.0152 - acc: 0.9952\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 22s 364us/step - loss: 0.0151 - acc: 0.9949\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 21s 351us/step - loss: 0.0129 - acc: 0.9956\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 22s 373us/step - loss: 0.0131 - acc: 0.9959\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 21s 352us/step - loss: 0.0104 - acc: 0.9963\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 21s 351us/step - loss: 0.0119 - acc: 0.9960\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 22s 360us/step - loss: 0.0110 - acc: 0.9962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6eaf5d7a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PS1IRoJhw6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c576a65b-56e5-4f89-8dee-6185f8d465ce"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0288882976109584, 0.9921]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCkzZ6acFSov",
        "colab_type": "text"
      },
      "source": [
        "## Vadidaton  Accuracy = 99.21"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFF6w13PoYW5",
        "colab_type": "text"
      },
      "source": [
        "## Result\n",
        "\n",
        "Here we are able to see some improvements from the previous network which we built. Our validation accuracy has increased from 99.15 to 99.21  We can say that some improvement in this network is seen. Batch Normalization and 1x1 conolutions really helped us.\n",
        "\n",
        "In the next network we will be building we will adding more improvements over this model architecture."
      ]
    }
  ]
}